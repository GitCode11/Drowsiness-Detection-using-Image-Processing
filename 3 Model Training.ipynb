{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, f1_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('D:/Minor/totalwithmaininfoNEWNEWNEW.csv')\n",
    "df = df.drop(df.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>PUC</th>\n",
       "      <th>PUC_N</th>\n",
       "      <th>MOE</th>\n",
       "      <th>MOE_N</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.257930</td>\n",
       "      <td>-0.264316</td>\n",
       "      <td>0.778621</td>\n",
       "      <td>0.682331</td>\n",
       "      <td>0.417689</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>3.018724</td>\n",
       "      <td>0.395741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274627</td>\n",
       "      <td>1.105607</td>\n",
       "      <td>0.745216</td>\n",
       "      <td>-1.147899</td>\n",
       "      <td>0.366795</td>\n",
       "      <td>-1.102199</td>\n",
       "      <td>2.713560</td>\n",
       "      <td>-1.137307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250898</td>\n",
       "      <td>-0.841291</td>\n",
       "      <td>0.774664</td>\n",
       "      <td>0.465568</td>\n",
       "      <td>0.402140</td>\n",
       "      <td>0.252993</td>\n",
       "      <td>3.087563</td>\n",
       "      <td>0.741567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>3.217887</td>\n",
       "      <td>0.688505</td>\n",
       "      <td>-4.255129</td>\n",
       "      <td>0.415034</td>\n",
       "      <td>0.747404</td>\n",
       "      <td>2.292181</td>\n",
       "      <td>-3.254179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293565</td>\n",
       "      <td>2.659484</td>\n",
       "      <td>0.704847</td>\n",
       "      <td>-3.359717</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>2.046805</td>\n",
       "      <td>2.400990</td>\n",
       "      <td>-2.707556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        EAR     EAR_N       MAR     MAR_N       PUC     PUC_N       MOE  \\\n",
       "0  0.257930 -0.264316  0.778621  0.682331  0.417689  0.849206  3.018724   \n",
       "1  0.274627  1.105607  0.745216 -1.147899  0.366795 -1.102199  2.713560   \n",
       "2  0.250898 -0.841291  0.774664  0.465568  0.402140  0.252993  3.087563   \n",
       "3  0.300371  3.217887  0.688505 -4.255129  0.415034  0.747404  2.292181   \n",
       "4  0.293565  2.659484  0.704847 -3.359717  0.448924  2.046805  2.400990   \n",
       "\n",
       "      MOE_N  Label  \n",
       "0  0.395741      0  \n",
       "1 -1.137307      0  \n",
       "2  0.741567      0  \n",
       "3 -3.254179      0  \n",
       "4 -2.707556      0  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Label\"].replace({10: 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_percentage = 15/19\n",
    "#train_index = int(len(df)*train_percentage)\n",
    "train_index=7160\n",
    "test_index = len(df)-train_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y=df[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X=df[[\"EAR\",\"MAR\",\"PUC\",\"MOE\",\"EAR_N\",\"MAR_N\",\"PUC_N\",\"MOE_N\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.model_selection import train_test_split\n",
    "#X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size = 0.1958,shuffle=True,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>PUC</th>\n",
       "      <th>PUC_N</th>\n",
       "      <th>MOE</th>\n",
       "      <th>MOE_N</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.257930</td>\n",
       "      <td>-0.264316</td>\n",
       "      <td>0.778621</td>\n",
       "      <td>0.682331</td>\n",
       "      <td>0.417689</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>3.018724</td>\n",
       "      <td>0.395741</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274627</td>\n",
       "      <td>1.105607</td>\n",
       "      <td>0.745216</td>\n",
       "      <td>-1.147899</td>\n",
       "      <td>0.366795</td>\n",
       "      <td>-1.102199</td>\n",
       "      <td>2.713560</td>\n",
       "      <td>-1.137307</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250898</td>\n",
       "      <td>-0.841291</td>\n",
       "      <td>0.774664</td>\n",
       "      <td>0.465568</td>\n",
       "      <td>0.402140</td>\n",
       "      <td>0.252993</td>\n",
       "      <td>3.087563</td>\n",
       "      <td>0.741567</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>3.217887</td>\n",
       "      <td>0.688505</td>\n",
       "      <td>-4.255129</td>\n",
       "      <td>0.415034</td>\n",
       "      <td>0.747404</td>\n",
       "      <td>2.292181</td>\n",
       "      <td>-3.254179</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293565</td>\n",
       "      <td>2.659484</td>\n",
       "      <td>0.704847</td>\n",
       "      <td>-3.359717</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>2.046805</td>\n",
       "      <td>2.400990</td>\n",
       "      <td>-2.707556</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7155</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>2.678521</td>\n",
       "      <td>0.901927</td>\n",
       "      <td>30.327099</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>1.675724</td>\n",
       "      <td>3.045677</td>\n",
       "      <td>-1.623052</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7156</td>\n",
       "      <td>0.324833</td>\n",
       "      <td>4.155270</td>\n",
       "      <td>0.874365</td>\n",
       "      <td>16.047977</td>\n",
       "      <td>0.477489</td>\n",
       "      <td>3.017775</td>\n",
       "      <td>2.691733</td>\n",
       "      <td>-2.979233</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7157</td>\n",
       "      <td>0.300075</td>\n",
       "      <td>2.881341</td>\n",
       "      <td>0.866377</td>\n",
       "      <td>11.909637</td>\n",
       "      <td>0.452734</td>\n",
       "      <td>2.073171</td>\n",
       "      <td>2.887201</td>\n",
       "      <td>-2.230274</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7158</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>3.095007</td>\n",
       "      <td>0.872064</td>\n",
       "      <td>14.855945</td>\n",
       "      <td>0.455013</td>\n",
       "      <td>2.160134</td>\n",
       "      <td>2.866486</td>\n",
       "      <td>-2.309647</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7159</td>\n",
       "      <td>0.299696</td>\n",
       "      <td>2.861838</td>\n",
       "      <td>0.877078</td>\n",
       "      <td>17.453423</td>\n",
       "      <td>0.443943</td>\n",
       "      <td>1.737705</td>\n",
       "      <td>2.926558</td>\n",
       "      <td>-2.079475</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7160 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EAR     EAR_N       MAR      MAR_N       PUC     PUC_N       MOE  \\\n",
       "0     0.257930 -0.264316  0.778621   0.682331  0.417689  0.849206  3.018724   \n",
       "1     0.274627  1.105607  0.745216  -1.147899  0.366795 -1.102199  2.713560   \n",
       "2     0.250898 -0.841291  0.774664   0.465568  0.402140  0.252993  3.087563   \n",
       "3     0.300371  3.217887  0.688505  -4.255129  0.415034  0.747404  2.292181   \n",
       "4     0.293565  2.659484  0.704847  -3.359717  0.448924  2.046805  2.400990   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "7155  0.296133  2.678521  0.901927  30.327099  0.442319  1.675724  3.045677   \n",
       "7156  0.324833  4.155270  0.874365  16.047977  0.477489  3.017775  2.691733   \n",
       "7157  0.300075  2.881341  0.866377  11.909637  0.452734  2.073171  2.887201   \n",
       "7158  0.304228  3.095007  0.872064  14.855945  0.455013  2.160134  2.866486   \n",
       "7159  0.299696  2.861838  0.877078  17.453423  0.443943  1.737705  2.926558   \n",
       "\n",
       "         MOE_N  Label  \n",
       "0     0.395741      0  \n",
       "1    -1.137307      0  \n",
       "2     0.741567      0  \n",
       "3    -3.254179      0  \n",
       "4    -2.707556      0  \n",
       "...        ...    ...  \n",
       "7155 -1.623052      1  \n",
       "7156 -2.979233      1  \n",
       "7157 -2.230274      1  \n",
       "7158 -2.309647      1  \n",
       "7159 -2.079475      1  \n",
       "\n",
       "[7160 rows x 9 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df[:train_index]\n",
    "df_test = df[-test_index:]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test.drop([\"Label\"],axis=1)\n",
    "Y_test = df_test[\"Label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop('Label',axis=1)\n",
    "Y_train = df_train['Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EAR</th>\n",
       "      <th>EAR_N</th>\n",
       "      <th>MAR</th>\n",
       "      <th>MAR_N</th>\n",
       "      <th>PUC</th>\n",
       "      <th>PUC_N</th>\n",
       "      <th>MOE</th>\n",
       "      <th>MOE_N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.257930</td>\n",
       "      <td>-0.264316</td>\n",
       "      <td>0.778621</td>\n",
       "      <td>0.682331</td>\n",
       "      <td>0.417689</td>\n",
       "      <td>0.849206</td>\n",
       "      <td>3.018724</td>\n",
       "      <td>0.395741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.274627</td>\n",
       "      <td>1.105607</td>\n",
       "      <td>0.745216</td>\n",
       "      <td>-1.147899</td>\n",
       "      <td>0.366795</td>\n",
       "      <td>-1.102199</td>\n",
       "      <td>2.713560</td>\n",
       "      <td>-1.137307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.250898</td>\n",
       "      <td>-0.841291</td>\n",
       "      <td>0.774664</td>\n",
       "      <td>0.465568</td>\n",
       "      <td>0.402140</td>\n",
       "      <td>0.252993</td>\n",
       "      <td>3.087563</td>\n",
       "      <td>0.741567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.300371</td>\n",
       "      <td>3.217887</td>\n",
       "      <td>0.688505</td>\n",
       "      <td>-4.255129</td>\n",
       "      <td>0.415034</td>\n",
       "      <td>0.747404</td>\n",
       "      <td>2.292181</td>\n",
       "      <td>-3.254179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.293565</td>\n",
       "      <td>2.659484</td>\n",
       "      <td>0.704847</td>\n",
       "      <td>-3.359717</td>\n",
       "      <td>0.448924</td>\n",
       "      <td>2.046805</td>\n",
       "      <td>2.400990</td>\n",
       "      <td>-2.707556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7155</td>\n",
       "      <td>0.296133</td>\n",
       "      <td>2.678521</td>\n",
       "      <td>0.901927</td>\n",
       "      <td>30.327099</td>\n",
       "      <td>0.442319</td>\n",
       "      <td>1.675724</td>\n",
       "      <td>3.045677</td>\n",
       "      <td>-1.623052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7156</td>\n",
       "      <td>0.324833</td>\n",
       "      <td>4.155270</td>\n",
       "      <td>0.874365</td>\n",
       "      <td>16.047977</td>\n",
       "      <td>0.477489</td>\n",
       "      <td>3.017775</td>\n",
       "      <td>2.691733</td>\n",
       "      <td>-2.979233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7157</td>\n",
       "      <td>0.300075</td>\n",
       "      <td>2.881341</td>\n",
       "      <td>0.866377</td>\n",
       "      <td>11.909637</td>\n",
       "      <td>0.452734</td>\n",
       "      <td>2.073171</td>\n",
       "      <td>2.887201</td>\n",
       "      <td>-2.230274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7158</td>\n",
       "      <td>0.304228</td>\n",
       "      <td>3.095007</td>\n",
       "      <td>0.872064</td>\n",
       "      <td>14.855945</td>\n",
       "      <td>0.455013</td>\n",
       "      <td>2.160134</td>\n",
       "      <td>2.866486</td>\n",
       "      <td>-2.309647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7159</td>\n",
       "      <td>0.299696</td>\n",
       "      <td>2.861838</td>\n",
       "      <td>0.877078</td>\n",
       "      <td>17.453423</td>\n",
       "      <td>0.443943</td>\n",
       "      <td>1.737705</td>\n",
       "      <td>2.926558</td>\n",
       "      <td>-2.079475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7160 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           EAR     EAR_N       MAR      MAR_N       PUC     PUC_N       MOE  \\\n",
       "0     0.257930 -0.264316  0.778621   0.682331  0.417689  0.849206  3.018724   \n",
       "1     0.274627  1.105607  0.745216  -1.147899  0.366795 -1.102199  2.713560   \n",
       "2     0.250898 -0.841291  0.774664   0.465568  0.402140  0.252993  3.087563   \n",
       "3     0.300371  3.217887  0.688505  -4.255129  0.415034  0.747404  2.292181   \n",
       "4     0.293565  2.659484  0.704847  -3.359717  0.448924  2.046805  2.400990   \n",
       "...        ...       ...       ...        ...       ...       ...       ...   \n",
       "7155  0.296133  2.678521  0.901927  30.327099  0.442319  1.675724  3.045677   \n",
       "7156  0.324833  4.155270  0.874365  16.047977  0.477489  3.017775  2.691733   \n",
       "7157  0.300075  2.881341  0.866377  11.909637  0.452734  2.073171  2.887201   \n",
       "7158  0.304228  3.095007  0.872064  14.855945  0.455013  2.160134  2.866486   \n",
       "7159  0.299696  2.861838  0.877078  17.453423  0.443943  1.737705  2.926558   \n",
       "\n",
       "         MOE_N  \n",
       "0     0.395741  \n",
       "1    -1.137307  \n",
       "2     0.741567  \n",
       "3    -3.254179  \n",
       "4    -2.707556  \n",
       "...        ...  \n",
       "7155 -1.623052  \n",
       "7156 -2.979233  \n",
       "7157 -2.230274  \n",
       "7158 -2.309647  \n",
       "7159 -2.079475  \n",
       "\n",
       "[7160 rows x 8 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average(y_pred):\n",
    "    for i in range(len(y_pred)):\n",
    "        if i % 240 == 0 or (i+1) % 240 == 0:\n",
    "            pass\n",
    "        else: \n",
    "            average = float(y_pred[i-1] + y_pred[i] + y_pred[i+1])/3\n",
    "            if average >= 0.5:\n",
    "                y_pred[i] = 1\n",
    "            else:\n",
    "                y_pred[i] = 0\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7567708333333333, 0.7463335143943508, 0.7878808593750001]\n",
      "[[766 194]\n",
      " [273 687]]\n"
     ]
    }
   ],
   "source": [
    "# Fitting Logistic Regression Model on training dataset\n",
    "clf = LogisticRegression().fit(X_train, Y_train)\n",
    "\n",
    "# Prediction on testing data\n",
    "y_pred_1 = clf.predict(X_test)\n",
    "\n",
    "# Averaging out the predictions\n",
    "y_pred_1 = average(y_pred_1)\n",
    "\n",
    "# Evaluation\n",
    "y_score_1 = clf.predict_proba(X_test)[:,1]\n",
    "acc1 = accuracy_score(Y_test, y_pred_1)\n",
    "f1_score_1 = metrics.f1_score(Y_test, y_pred_1)\n",
    "roc_1 = metrics.roc_auc_score(Y_test, y_score_1)\n",
    "\n",
    "print([acc1,f1_score_1,roc_1])\n",
    "print(confusion_matrix(Y_test, y_pred_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['LogReg_model.pkl']"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.externals import joblib\n",
    "\n",
    "joblib_file = \"LogReg_model.pkl\"\n",
    "joblib.dump(clf, joblib_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6479166666666667, 0.5961768219832736, 0.6516097005208332]\n",
      "[[745 215]\n",
      " [461 499]]\n"
     ]
    }
   ],
   "source": [
    "clf_NB = GaussianNB()\n",
    "clf_NB.fit(X_train, Y_train)\n",
    "\n",
    "pred_NB = clf_NB.predict(X_test)\n",
    "pred_NB = average(pred_NB)\n",
    "\n",
    "y_score_2 = clf_NB.predict_proba(X_test)[:,1]\n",
    "acc2 = accuracy_score(Y_test, pred_NB)\n",
    "f1_score_2 = metrics.f1_score(Y_test, pred_NB)\n",
    "roc_2 = metrics.roc_auc_score(Y_test, y_score_2)\n",
    "\n",
    "print([acc2,f1_score_2,roc_2])\n",
    "print(confusion_matrix(Y_test, pred_NB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc3_list = []\n",
    "f1_score3_list = []\n",
    "roc_3_list = []\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "for i in range(1,30):\n",
    "    neigh = KNeighborsClassifier(n_neighbors=i)\n",
    "    neigh.fit(X_train, Y_train) \n",
    "    pred_KN = neigh.predict(X_test)\n",
    "    pred_KN = average(pred_KN)\n",
    "    y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "    acc3_list.append(accuracy_score(Y_test, pred_KN))\n",
    "    f1_score3_list.append(metrics.f1_score(Y_test, pred_KN))\n",
    "    roc_3_list.append(metrics.roc_auc_score(Y_test, y_score_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc3_list.index(max(acc3_list))+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6515625, 0.6766553890768486, 0.6170030381944445]\n",
      "[[551 409]\n",
      " [260 700]]\n"
     ]
    }
   ],
   "source": [
    "neigh = KNeighborsClassifier(n_neighbors=acc3_list.index(max(acc3_list))+1)\n",
    "neigh.fit(X_train, Y_train) \n",
    "pred_KN = neigh.predict(X_test)\n",
    "pred_KN = average(pred_KN)\n",
    "y_score_3 = neigh.predict_proba(X_test)[:,1]\n",
    "acc3 = accuracy_score(Y_test, pred_KN)\n",
    "f1_score_3 = metrics.f1_score(Y_test, pred_KN)\n",
    "roc_3 = metrics.roc_auc_score(Y_test, y_score_3)\n",
    "print([acc3,f1_score_3,roc_3])\n",
    "print(confusion_matrix(Y_test, pred_KN))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "F1_score_4_list = []\n",
    "acc4_list = []\n",
    "roc_4_list = []\n",
    "mlp = []\n",
    "# CAN ADD MAX_ITER parameter\n",
    "hidden_units = [10,20,30,40,50,60,70]\n",
    "optimizer = ['sgd','adam','lbfgs']\n",
    "activation = ['logistic','tanh','relu']\n",
    "for j in activation:\n",
    "    for i in optimizer:\n",
    "        for k in hidden_units:\n",
    "            clf_MLP = MLPClassifier(hidden_layer_sizes= k, activation =  j, solver= i)\n",
    "            clf_MLP.fit(X_train, Y_train)\n",
    "            pred_MLP = clf_MLP.predict(X_test)\n",
    "            pred_MLP = average(pred_MLP)\n",
    "            y_score_4 = clf_MLP.predict_proba(X_test)[:,1]\n",
    "            acc4_list.append(accuracy_score(Y_test,pred_MLP))\n",
    "            roc_4_list.append(metrics.roc_auc_score(Y_test, y_score_4))\n",
    "            F1_score_4_list.append(metrics.f1_score(Y_test, pred_MLP))\n",
    "            mlp.append([j,i,k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy:  0.8020833333333334\n",
      "Best Combination: ['relu', 'sgd', 50]\n"
     ]
    }
   ],
   "source": [
    "print(\"Best Accuracy: \", max(acc4_list))\n",
    "min_index = acc4_list.index(max(acc4_list))\n",
    "print(\"Best Combination:\", mlp[min_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.68125, 0.7262969588550984, 0.6942154947916666]\n",
      "[[496 464]\n",
      " [148 812]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\neural_network\\multilayer_perceptron.py:566: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  % self.max_iter, ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "clf_MLP = MLPClassifier(hidden_layer_sizes= mlp[min_index][2], activation =  mlp[min_index][0], solver= mlp[min_index][1])\n",
    "clf_MLP.fit(X_train, Y_train)\n",
    "pred_MLP = clf_MLP.predict(X_test)\n",
    "pred_MLP = average(pred_MLP)\n",
    "y_score_4 = clf_MLP.predict_proba(X_test)[:,1]\n",
    "acc4 = accuracy_score(Y_test,pred_MLP)\n",
    "f1_score_4 = metrics.f1_score(Y_test, pred_MLP)\n",
    "roc_4 = metrics.roc_auc_score(Y_test, y_score_4)\n",
    "print([acc4,f1_score_4,roc_4])\n",
    "print(confusion_matrix(Y_test, pred_MLP))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6541666666666667\n"
     ]
    }
   ],
   "source": [
    "acc5=[]\n",
    "max_depth = []\n",
    "for i in [2,3,4,5,6,7,8,9,10]:\n",
    "    clf_DT = DecisionTreeClassifier(random_state=0, max_depth = i)\n",
    "    clf_DT.fit(X_train, Y_train)\n",
    "    pred_DT = clf_DT.predict(X_test)\n",
    "    pred_DT = average(pred_DT)\n",
    "    acc5.append(accuracy_score(pred_DT, Y_test))\n",
    "    max_depth.append(i)\n",
    "print (max(acc5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_depth = max_depth[acc5.index(max(acc5))]\n",
    "best_depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6541666666666667, 0.6422413793103449, 0.6460026041666665]\n",
      "[[660 300]\n",
      " [364 596]]\n"
     ]
    }
   ],
   "source": [
    "clf_DT = DecisionTreeClassifier(random_state=0, max_depth = best_depth)\n",
    "clf_DT.fit(X_train, Y_train)\n",
    "pred_DT = clf_DT.predict(X_test)\n",
    "pred_DT = average(pred_DT)\n",
    "y_score_5 = clf_DT.predict_proba(X_test)[:,1]\n",
    "acc5 = accuracy_score(Y_test, pred_DT)\n",
    "f1_score_5 = metrics.f1_score(Y_test, pred_DT)\n",
    "roc_5 = metrics.roc_auc_score(Y_test, y_score_5)\n",
    "print([acc5,f1_score_5,roc_5])\n",
    "print(confusion_matrix(Y_test, pred_DT))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6692708333333334\n"
     ]
    }
   ],
   "source": [
    "acc6=[]\n",
    "max_depth = []\n",
    "for i in range(1,10):\n",
    "    clf_RF = RandomForestClassifier(max_depth=i)\n",
    "    clf_RF.fit(X_train, Y_train) \n",
    "    pred_RF = clf_RF.predict(X_test)\n",
    "    pred_RF = average(pred_RF)\n",
    "    acc6.append(accuracy_score(pred_RF, Y_test))\n",
    "    max_depth.append(i)\n",
    "print (max(acc6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_depth_6 = max_depth[acc6.index(max(acc6))]\n",
    "best_depth_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sagar\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6755208333333333, 0.7169468423443889, 0.6484445529513889]\n",
      "[[508 452]\n",
      " [171 789]]\n"
     ]
    }
   ],
   "source": [
    "clf_RF = RandomForestClassifier(max_depth=best_depth_6)\n",
    "clf_RF.fit(X_train, Y_train) \n",
    "pred_RF = clf_RF.predict(X_test)\n",
    "pred_RF = average(pred_RF)\n",
    "y_score_6 = clf_RF.predict_proba(X_test)[:,1]\n",
    "acc6 = accuracy_score(Y_test, pred_RF)\n",
    "f1_score_6 = metrics.f1_score(Y_test, pred_RF)\n",
    "roc_6 = metrics.roc_auc_score(Y_test, y_score_6)\n",
    "print([acc6,f1_score_6,roc_6])\n",
    "print(confusion_matrix(Y_test, pred_RF))\n",
    "\n",
    "feature_importances = pd.DataFrame(clf_RF.feature_importances_,index = X_train.columns,columns=['Importance']).sort_values('Importance',ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.671875, 0.6974063400576369, 0.6789860026041667]\n",
      "[[564 396]\n",
      " [234 726]]\n"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "clf_XGB = XGBClassifier()\n",
    "clf_XGB.fit(X_train, Y_train)\n",
    "pred_XGB = clf_XGB.predict(X_test)\n",
    "pred_XGB = average(pred_XGB)\n",
    "y_score_8 = clf_XGB.predict_proba(X_test)[:,1]\n",
    "acc8 = accuracy_score(Y_test,pred_XGB)\n",
    "f1_score_8 = metrics.f1_score(Y_test, pred_XGB)\n",
    "roc_8 = metrics.roc_auc_score(Y_test, y_score_8)\n",
    "print([acc8,f1_score_8,roc_8])\n",
    "print(confusion_matrix(Y_test, pred_XGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>MOE_N</td>\n",
       "      <td>0.196819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PUC_N</td>\n",
       "      <td>0.172176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EAR_N</td>\n",
       "      <td>0.129307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MAR_N</td>\n",
       "      <td>0.128964</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MAR</td>\n",
       "      <td>0.114888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MOE</td>\n",
       "      <td>0.094561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>EAR</td>\n",
       "      <td>0.092264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>PUC</td>\n",
       "      <td>0.071022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Importance\n",
       "MOE_N    0.196819\n",
       "PUC_N    0.172176\n",
       "EAR_N    0.129307\n",
       "MAR_N    0.128964\n",
       "MAR      0.114888\n",
       "MOE      0.094561\n",
       "EAR      0.092264\n",
       "PUC      0.071022"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7160, 8, 1)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_shaped = np.expand_dims(X_train, axis=2)\n",
    "X_train_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1920, 8, 1)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_shaped = np.expand_dims(X_test, axis=2)\n",
    "X_test_shaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "224/224 [==============================] - 2s 7ms/step - loss: 0.9081 - accuracy: 0.4659 - val_loss: 0.8802 - val_accuracy: 0.4349\n",
      "Epoch 2/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.7708 - accuracy: 0.5254 - val_loss: 0.7823 - val_accuracy: 0.4839\n",
      "Epoch 3/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.6874 - accuracy: 0.6035 - val_loss: 0.7496 - val_accuracy: 0.5354\n",
      "Epoch 4/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.6530 - accuracy: 0.6682 - val_loss: 0.7337 - val_accuracy: 0.6000\n",
      "Epoch 5/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.6316 - accuracy: 0.7025 - val_loss: 0.7341 - val_accuracy: 0.6099\n",
      "Epoch 6/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.6212 - accuracy: 0.7144 - val_loss: 0.7355 - val_accuracy: 0.6135\n",
      "Epoch 7/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.6105 - accuracy: 0.7223 - val_loss: 0.7352 - val_accuracy: 0.6182\n",
      "Epoch 8/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5970 - accuracy: 0.7232 - val_loss: 0.7334 - val_accuracy: 0.6245\n",
      "Epoch 9/100\n",
      "224/224 [==============================] - 1s 5ms/step - loss: 0.5900 - accuracy: 0.7318 - val_loss: 0.7349 - val_accuracy: 0.6307\n",
      "Epoch 10/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5827 - accuracy: 0.7303 - val_loss: 0.7365 - val_accuracy: 0.6380\n",
      "Epoch 11/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5796 - accuracy: 0.7331 - val_loss: 0.7373 - val_accuracy: 0.6406\n",
      "Epoch 12/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.7334 - val_loss: 0.7397 - val_accuracy: 0.6422\n",
      "Epoch 13/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5695 - accuracy: 0.7398 - val_loss: 0.7413 - val_accuracy: 0.6422\n",
      "Epoch 14/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5651 - accuracy: 0.7420 - val_loss: 0.7429 - val_accuracy: 0.6443\n",
      "Epoch 15/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5625 - accuracy: 0.7404 - val_loss: 0.7412 - val_accuracy: 0.6464\n",
      "Epoch 16/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5568 - accuracy: 0.7475 - val_loss: 0.7408 - val_accuracy: 0.6458\n",
      "Epoch 17/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5543 - accuracy: 0.7482 - val_loss: 0.7399 - val_accuracy: 0.6458\n",
      "Epoch 18/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5509 - accuracy: 0.7426 - val_loss: 0.7374 - val_accuracy: 0.6453\n",
      "Epoch 19/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.5495 - accuracy: 0.7448 - val_loss: 0.7369 - val_accuracy: 0.6448\n",
      "Epoch 20/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5454 - accuracy: 0.7493 - val_loss: 0.7369 - val_accuracy: 0.6448\n",
      "Epoch 21/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5443 - accuracy: 0.7487 - val_loss: 0.7359 - val_accuracy: 0.6448\n",
      "Epoch 22/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5444 - accuracy: 0.7503 - val_loss: 0.7380 - val_accuracy: 0.6448\n",
      "Epoch 23/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5403 - accuracy: 0.7508 - val_loss: 0.7369 - val_accuracy: 0.6458\n",
      "Epoch 24/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5398 - accuracy: 0.7487 - val_loss: 0.7374 - val_accuracy: 0.6448\n",
      "Epoch 25/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5396 - accuracy: 0.7528 - val_loss: 0.7351 - val_accuracy: 0.6453\n",
      "Epoch 26/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5354 - accuracy: 0.7511 - val_loss: 0.7359 - val_accuracy: 0.6474\n",
      "Epoch 27/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5357 - accuracy: 0.7567 - val_loss: 0.7350 - val_accuracy: 0.6448\n",
      "Epoch 28/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5332 - accuracy: 0.7575 - val_loss: 0.7331 - val_accuracy: 0.6469\n",
      "Epoch 29/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5312 - accuracy: 0.7522 - val_loss: 0.7325 - val_accuracy: 0.6469\n",
      "Epoch 30/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5295 - accuracy: 0.7527 - val_loss: 0.7345 - val_accuracy: 0.6469\n",
      "Epoch 31/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.5292 - accuracy: 0.7546 - val_loss: 0.7339 - val_accuracy: 0.6464\n",
      "Epoch 32/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5297 - accuracy: 0.7528 - val_loss: 0.7338 - val_accuracy: 0.6458\n",
      "Epoch 33/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5272 - accuracy: 0.7553 - val_loss: 0.7320 - val_accuracy: 0.6484\n",
      "Epoch 34/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5241 - accuracy: 0.7577 - val_loss: 0.7312 - val_accuracy: 0.6484\n",
      "Epoch 35/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5273 - accuracy: 0.7536 - val_loss: 0.7323 - val_accuracy: 0.6474\n",
      "Epoch 36/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5240 - accuracy: 0.7511 - val_loss: 0.7321 - val_accuracy: 0.6474\n",
      "Epoch 37/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5217 - accuracy: 0.7587 - val_loss: 0.7291 - val_accuracy: 0.6474\n",
      "Epoch 38/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5206 - accuracy: 0.7580 - val_loss: 0.7267 - val_accuracy: 0.6479\n",
      "Epoch 39/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5233 - accuracy: 0.7582 - val_loss: 0.7265 - val_accuracy: 0.6484\n",
      "Epoch 40/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.5229 - accuracy: 0.7573 - val_loss: 0.7217 - val_accuracy: 0.6479\n",
      "Epoch 41/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5190 - accuracy: 0.7608 - val_loss: 0.7233 - val_accuracy: 0.6479\n",
      "Epoch 42/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5191 - accuracy: 0.7580 - val_loss: 0.7191 - val_accuracy: 0.6479\n",
      "Epoch 43/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5204 - accuracy: 0.7609 - val_loss: 0.7219 - val_accuracy: 0.6479\n",
      "Epoch 44/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5180 - accuracy: 0.7581 - val_loss: 0.7222 - val_accuracy: 0.6479\n",
      "Epoch 45/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5161 - accuracy: 0.7615 - val_loss: 0.7236 - val_accuracy: 0.6474\n",
      "Epoch 46/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5165 - accuracy: 0.7594 - val_loss: 0.7231 - val_accuracy: 0.6474\n",
      "Epoch 47/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5140 - accuracy: 0.7609 - val_loss: 0.7237 - val_accuracy: 0.6469\n",
      "Epoch 48/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.5135 - accuracy: 0.7592 - val_loss: 0.7239 - val_accuracy: 0.6484\n",
      "Epoch 49/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5142 - accuracy: 0.7594 - val_loss: 0.7242 - val_accuracy: 0.6484\n",
      "Epoch 50/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5099 - accuracy: 0.7596 - val_loss: 0.7233 - val_accuracy: 0.6484\n",
      "Epoch 51/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5099 - accuracy: 0.7640 - val_loss: 0.7241 - val_accuracy: 0.6484\n",
      "Epoch 52/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5108 - accuracy: 0.7615 - val_loss: 0.7241 - val_accuracy: 0.6484\n",
      "Epoch 53/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5118 - accuracy: 0.7601 - val_loss: 0.7238 - val_accuracy: 0.6479\n",
      "Epoch 54/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5082 - accuracy: 0.7616 - val_loss: 0.7226 - val_accuracy: 0.6474\n",
      "Epoch 55/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5107 - accuracy: 0.7651 - val_loss: 0.7205 - val_accuracy: 0.6474\n",
      "Epoch 56/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5097 - accuracy: 0.7656 - val_loss: 0.7172 - val_accuracy: 0.6479\n",
      "Epoch 57/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5065 - accuracy: 0.7647 - val_loss: 0.7183 - val_accuracy: 0.6479\n",
      "Epoch 58/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5061 - accuracy: 0.7627 - val_loss: 0.7181 - val_accuracy: 0.6479\n",
      "Epoch 59/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5045 - accuracy: 0.7620 - val_loss: 0.7176 - val_accuracy: 0.6479\n",
      "Epoch 60/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5073 - accuracy: 0.7627 - val_loss: 0.7183 - val_accuracy: 0.6474\n",
      "Epoch 61/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5057 - accuracy: 0.7627 - val_loss: 0.7148 - val_accuracy: 0.6479\n",
      "Epoch 62/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5054 - accuracy: 0.7641 - val_loss: 0.7132 - val_accuracy: 0.6490\n",
      "Epoch 63/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5058 - accuracy: 0.7651 - val_loss: 0.7121 - val_accuracy: 0.6474\n",
      "Epoch 64/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.7647 - val_loss: 0.7140 - val_accuracy: 0.6474\n",
      "Epoch 65/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.7637 - val_loss: 0.7127 - val_accuracy: 0.6484\n",
      "Epoch 66/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5051 - accuracy: 0.7661 - val_loss: 0.7137 - val_accuracy: 0.6495\n",
      "Epoch 67/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5024 - accuracy: 0.7658 - val_loss: 0.7128 - val_accuracy: 0.6495\n",
      "Epoch 68/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5002 - accuracy: 0.7658 - val_loss: 0.7129 - val_accuracy: 0.6479\n",
      "Epoch 69/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5011 - accuracy: 0.7666 - val_loss: 0.7125 - val_accuracy: 0.6490\n",
      "Epoch 70/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.7668 - val_loss: 0.7128 - val_accuracy: 0.6490\n",
      "Epoch 71/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5044 - accuracy: 0.7669 - val_loss: 0.7105 - val_accuracy: 0.6479\n",
      "Epoch 72/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5008 - accuracy: 0.7697 - val_loss: 0.7100 - val_accuracy: 0.6474\n",
      "Epoch 73/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.7709 - val_loss: 0.7113 - val_accuracy: 0.6474\n",
      "Epoch 74/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5001 - accuracy: 0.7677 - val_loss: 0.7083 - val_accuracy: 0.6484\n",
      "Epoch 75/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5010 - accuracy: 0.7682 - val_loss: 0.7080 - val_accuracy: 0.6484\n",
      "Epoch 76/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4998 - accuracy: 0.7680 - val_loss: 0.7081 - val_accuracy: 0.6484\n",
      "Epoch 77/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.5015 - accuracy: 0.7668 - val_loss: 0.7074 - val_accuracy: 0.6484\n",
      "Epoch 78/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4954 - accuracy: 0.7682 - val_loss: 0.7074 - val_accuracy: 0.6490\n",
      "Epoch 79/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.4980 - accuracy: 0.7687 - val_loss: 0.7062 - val_accuracy: 0.6484\n",
      "Epoch 80/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4964 - accuracy: 0.7679 - val_loss: 0.7113 - val_accuracy: 0.6479\n",
      "Epoch 81/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4972 - accuracy: 0.7712 - val_loss: 0.7066 - val_accuracy: 0.6490\n",
      "Epoch 82/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4987 - accuracy: 0.7642 - val_loss: 0.7065 - val_accuracy: 0.6474\n",
      "Epoch 83/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4962 - accuracy: 0.7716 - val_loss: 0.7057 - val_accuracy: 0.6490\n",
      "Epoch 84/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4951 - accuracy: 0.7712 - val_loss: 0.7047 - val_accuracy: 0.6484\n",
      "Epoch 85/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4961 - accuracy: 0.7684 - val_loss: 0.7053 - val_accuracy: 0.6490\n",
      "Epoch 86/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4958 - accuracy: 0.7721 - val_loss: 0.7041 - val_accuracy: 0.6490\n",
      "Epoch 87/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4945 - accuracy: 0.7669 - val_loss: 0.7043 - val_accuracy: 0.6484\n",
      "Epoch 88/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4960 - accuracy: 0.7687 - val_loss: 0.7025 - val_accuracy: 0.6479\n",
      "Epoch 89/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4966 - accuracy: 0.7672 - val_loss: 0.7036 - val_accuracy: 0.6484\n",
      "Epoch 90/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4970 - accuracy: 0.7716 - val_loss: 0.7038 - val_accuracy: 0.6484\n",
      "Epoch 91/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4959 - accuracy: 0.7729 - val_loss: 0.7037 - val_accuracy: 0.6490\n",
      "Epoch 92/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4940 - accuracy: 0.7686 - val_loss: 0.7038 - val_accuracy: 0.6484\n",
      "Epoch 93/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.4952 - accuracy: 0.7707 - val_loss: 0.7030 - val_accuracy: 0.6500\n",
      "Epoch 94/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4939 - accuracy: 0.7708 - val_loss: 0.7024 - val_accuracy: 0.6495\n",
      "Epoch 95/100\n",
      "224/224 [==============================] - 1s 4ms/step - loss: 0.4914 - accuracy: 0.7709 - val_loss: 0.7035 - val_accuracy: 0.6495\n",
      "Epoch 96/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4908 - accuracy: 0.7721 - val_loss: 0.7034 - val_accuracy: 0.6495\n",
      "Epoch 97/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4877 - accuracy: 0.7747 - val_loss: 0.7029 - val_accuracy: 0.6516\n",
      "Epoch 98/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4916 - accuracy: 0.7714 - val_loss: 0.7021 - val_accuracy: 0.6536\n",
      "Epoch 99/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4923 - accuracy: 0.7725 - val_loss: 0.7017 - val_accuracy: 0.6521\n",
      "Epoch 100/100\n",
      "224/224 [==============================] - 1s 3ms/step - loss: 0.4890 - accuracy: 0.7758 - val_loss: 0.7009 - val_accuracy: 0.6516\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2062591ae88>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv1D\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv1D(64, kernel_size = 3, activation = 'relu', input_shape = (8,1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation = 'relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))\n",
    "\n",
    "optimizer = Adam(lr=0.00001)\n",
    "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train_shaped, Y_train, validation_data = (X_test_shaped,Y_test), epochs = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_2 (Conv1D)            (None, 6, 64)             256       \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 384)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 32)                12320     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 13,121\n",
      "Trainable params: 13,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.665625, 0.7186678352322524, 0.6837207031249999]\n",
      "[[458 502]\n",
      " [140 820]]\n"
     ]
    }
   ],
   "source": [
    "pred_cnn = model.predict_classes(X_test_shaped)\n",
    "pred_cnn = average(pred_cnn)\n",
    "y_score_7 = model.predict_proba(X_test_shaped)\n",
    "acc7 = accuracy_score(Y_test, np.array(pred_cnn))\n",
    "f1_score_7 = metrics.f1_score(Y_test, pred_cnn)\n",
    "roc_7 = metrics.roc_auc_score(Y_test, y_score_7)\n",
    "print([acc7,f1_score_7,roc_7])\n",
    "print(confusion_matrix(Y_test, pred_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Model</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.756771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.647917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>KNN</td>\n",
       "      <td>0.651563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>MLP</td>\n",
       "      <td>0.681250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.654167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.675521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>CNN</td>\n",
       "      <td>0.665625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>XGB Boosting</td>\n",
       "      <td>0.671875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Accuracy\n",
       "Model                        \n",
       "Logistic Regression  0.756771\n",
       "Naive Bayes          0.647917\n",
       "KNN                  0.651563\n",
       "MLP                  0.681250\n",
       "Decision Tree        0.654167\n",
       "Random Forest        0.675521\n",
       "CNN                  0.665625\n",
       "XGB Boosting         0.671875"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_total = {'Model':['Logistic Regression','Naive Bayes', 'KNN', 'MLP','Decision Tree','Random Forest', 'CNN', 'XGB Boosting'],\n",
    "        'Accuracy':[acc1,acc2, acc3, acc4, acc5,acc6,acc7, acc8]}\n",
    "acc_total=pd.DataFrame(acc_total)\n",
    "acc_total=acc_total.set_index('Model')\n",
    "acc_total\n",
    "plt.plot(acc_total['Accuracy'])\n",
    "plt.xticks(rotation=45)\n",
    "acc_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
